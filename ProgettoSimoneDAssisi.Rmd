---
title: "ProgettoSimoneDAssisi"
output: html_document
---

```{r}
#STUDIO ED ANALISI DI DATASET LEGATO AL PHISHING
#Author: Simone D'Assisi
```

```{r}
# INSTALLAZIONE PACCHETTI
packages <- c("corrplot", "tidyverse", "ggplot2", "DataExplorer")

install.packages(setdiff(packages, rownames(installed.packages())))

# Caricamento delle librerie
library(tidyverse)  # Per manipolazione e visualizzazione dei dati
library(corrplot)   # Per la visualizzazione delle correlazioni
library(ggplot2)    # Per la creazione di grafici
library(DataExplorer)  # Per report automatici sull'EDA

```

```{r}

#ANALISI DESCRITTIVA DEL DATASET

#FASE 1: In questa fase il Dataset viene caricato e viene mostrato se sono presenti valori mancanti

# Caricamento del dataset
phishing_data <- read.csv("Phishing_URL_Dataset_2.csv", sep = ";")

# Visualizzare le prime righe del dataset
head(phishing_data)

# Verifica della struttura del dataset
str(phishing_data)

# Controllo dei valori mancanti
colSums(is.na(phishing_data))

```

```{r}

# FASE 2: vengono analizzate le feature che hanno un valore predittivo maggiore

# Codifica numerica delle colonne 'Domain' e 'Title'  per la creazione della matrice di correlazione
phishing_data$Domain_numeric <- as.numeric(factor(phishing_data$Domain))
phishing_data$Title_numeric <- as.numeric(factor(phishing_data$Title))

# CORRELAZIONE TRA TUTTE LE FEATURE E LA VARIABILE TARGET

# Esclusione delle variabili non numeriche
numeric_data <- phishing_data[sapply(phishing_data, is.numeric)]

label_correlation <- correlation_matrix["label", ]
sorted_label_correlation <- sort(label_correlation, decreasing = TRUE)
print(sorted_label_correlation)

# Selezione delle 5 feature piÃ¹ correlate con la variabile target
top_features <- names(sorted_label_correlation[1:6])


```

```{r}

# Esegui la selezione delle feature
top_features_data <- phishing_data[, top_features]

# FASE 3: Calcolo delle distribuzioni di Frequenza

for (feature in top_features) {
  if(feature != "URLSimilarityIndex"){
    # Calcolo la frequenza dei valori 0 e 1
    feature_counts <- table(phishing_data[[feature]])
    
    # Barplot per le feature binarie (0 e 1)
    barplot(feature_counts,
            main = paste("Distribuzione della Feature:", feature),
            col = c("#00AFBB", "#E7B800"),
            names.arg = names(feature_counts),
            xlab = feature,
            ylab = "Frequenza")
  
    # frequenza relativa
    feature_relative <- feature_counts / sum(feature_counts)
    
    print(feature)
    print("Frequenza Assoluta:")
    print(feature_counts)
    print("Frequenza Relativa:")
    print(feature_relative)
  }
}

# URLSimilarityIndex
bins <- seq(0, 100, by = 10)

phishing_data$URLSimilarityIndexClass <- cut(phishing_data$URLSimilarityIndex, 
                                             breaks = bins, 
                                             include.lowest = TRUE, 
                                             right = FALSE, 
                                             labels = paste0("[", bins[-length(bins)], "-", bins[-1], ")"))

# Calcola le frequenze per ciascun intervallo
class_counts <- table(phishing_data$URLSimilarityIndexClass)

# Crea un barplot per visualizzare la distribuzione delle classi di URLSimilarityIndex
barplot(class_counts,
        main = "Distribuzione di URLSimilarityIndex in classi",
        col = "#00AFBB",
        xlab = "Intervallo di URLSimilarityIndex",
        ylab = "Frequenza")  # 'las = 2' per ruotare le etichette dell'asse X

# Calcola le frequenze relative per ciascun intervallo
class_relative <- class_counts / sum(class_counts)

# Stampa le frequenze assolute e relative
print("Frequenze assolute per URLSimilarityIndex:")
print(class_counts)
print("Frequenze relative per URLSimilarityIndex:")
print(class_relative)


```

```{r}
# FASE 4: calcolo degli indici di sintesi

# Indici per le feature binarie
for (feature in top_features) {
  if (feature != "URLSimilarityIndex") {
    # Calcolo la media
    media_bin <- mean(phishing_data[[feature]])
    
    # Calcolo la varianza
    var_bin <- var(phishing_data[[feature]])
    
    # Calcolo la deviazione standard
    sd_bin <- sd(phishing_data[[feature]])
    
    # Calcolo la moda
    moda_bin <- names(which.max(table(phishing_data[[feature]])))
    
    # Stampa dei risultati
    cat("\nFeature:", feature, "\n")
    cat("Media:", round(media_bin, 4), "\n")
    cat("Varianza:", round(var_bin, 4), "\n")
    cat("Deviaizone Standard:", round(sd_bin, 4), "\n")
    cat("Moda:", moda_bin, "\n")
  }
}

# Indici per URLSimilarityIndex
mean_url <- mean(phishing_data$URLSimilarityIndex)
median_url <- median(phishing_data$URLSimilarityIndex)
mode_url <- as.numeric(names(sort(table(phishing_data$URLSimilarityIndex), decreasing = TRUE)[1]))
var_url <- var(phishing_data$URLSimilarityIndex)
sd_url <- sd(phishing_data$URLSimilarityIndex)
min_url <- min(phishing_data$URLSimilarityIndex)
max_url <- max(phishing_data$URLSimilarityIndex)
quantiles_url <- quantile(phishing_data$URLSimilarityIndex, probs = c(0.25, 0.75))

# Stampa dei risultati
cat("\nIndice di sintesi per URLSimilarityIndex:\n")
cat("Media:", round(mean_url, 4), "\n")
cat("Mediana:", round(median_url, 4), "\n")
cat("Moda:", mode_url, "\n")
cat("Varianza:", round(var_url, 4), "\n")
cat("Deviazione Standard:", round(sd_url, 4), "\n")
cat("Valore Minimo:", min_url, "\n")
cat("Valore Massimo:", max_url, "\n")
cat("Primo Quartile (Q1):", quantiles_url[1], "\n")
cat("Terzo Quartile (Q3):", quantiles_url[2], "\n")

```